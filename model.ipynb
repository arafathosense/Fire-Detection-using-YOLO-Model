{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting inference...\n",
      "âœ… Done. Saved to: D:\\ERU\\AitronixEnv\\Fire Detection system\\fire_output.mp4\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# ================== Paths ==================\n",
    "MODEL_PATH = r\"D:\\ERU\\AitronixEnv\\Fire Detection system\\best.pt\"\n",
    "INPUT_VIDEO = r\"D:\\ERU\\AitronixEnv\\Fire Detection system\\fire.mp4\"\n",
    "OUTPUT_VIDEO = r\"D:\\ERU\\AitronixEnv\\Fire Detection system\\fire_output.mp4\"\n",
    "\n",
    "# ================== Config ==================\n",
    "CONF_THRESH = 0.25\n",
    "IMGSZ = 640\n",
    "\n",
    "# ================== Load Model ==================\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "# ================== Video IO ==================\n",
    "cap = cv2.VideoCapture(INPUT_VIDEO)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"âŒ Cannot open video\")\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "fps = fps if fps > 0 else 25.0\n",
    "\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(OUTPUT_VIDEO, fourcc, fps, (w, h))\n",
    "\n",
    "# ================== Display ==================\n",
    "cv2.namedWindow(\"Output\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"Output\", 1280, 720)\n",
    "\n",
    "print(\"ðŸš€ Starting inference...\")\n",
    "\n",
    "# ================== Colors ==================\n",
    "COLORS = {\n",
    "    \"fire\": (0, 0, 255),    # ðŸ”´ Red\n",
    "    \"smoke\": (255, 0, 0)    # ðŸ”µ Blue\n",
    "}\n",
    "\n",
    "# ================== Loop ==================\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model.predict(\n",
    "        frame,\n",
    "        imgsz=IMGSZ,\n",
    "        conf=CONF_THRESH,\n",
    "        stream=True,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    for r in results:\n",
    "        if r.boxes is None:\n",
    "            continue\n",
    "\n",
    "        boxes = r.boxes.xyxy.cpu().numpy().astype(int)\n",
    "        confs = r.boxes.conf.cpu().numpy()\n",
    "        clss = r.boxes.cls.cpu().numpy().astype(int)\n",
    "\n",
    "        for (x1, y1, x2, y2), conf, cls in zip(boxes, confs, clss):\n",
    "            class_name = model.names[cls]\n",
    "            color = COLORS.get(class_name, (0, 255, 0))\n",
    "\n",
    "            label = f\"{class_name.upper()} {conf:.2f}\"\n",
    "\n",
    "            # ===== Text size =====\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 0.55\n",
    "            thickness = 1\n",
    "\n",
    "            (tw, th), baseline = cv2.getTextSize(label, font, font_scale, thickness)\n",
    "\n",
    "            # ===== Label background (inside box) =====\n",
    "            cv2.rectangle(\n",
    "                frame,\n",
    "                (x1, y1),\n",
    "                (x1 + tw + 6, y1 + th + baseline + 6),\n",
    "                color,\n",
    "                -1\n",
    "            )\n",
    "\n",
    "            # ===== Label text =====\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                label,\n",
    "                (x1 + 3, y1 + th + 3),\n",
    "                font,\n",
    "                font_scale,\n",
    "                (255, 255, 255),\n",
    "                thickness,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "\n",
    "            # ===== Bounding box =====\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "    out.write(frame)\n",
    "    cv2.imshow(\"Output\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# ================== Cleanup ==================\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"âœ… Done. Saved to:\", OUTPUT_VIDEO)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
